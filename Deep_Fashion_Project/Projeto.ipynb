{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "# IMPORTS\n",
    "\n",
    "import numpy as np\n",
    "import os\n",
    "import codecs  # Needs to be imported because of chinese characters\n",
    "import pandas as pd\n",
    "from PIL import *\n",
    "import pickle\n",
    "import time\n",
    "import cv2\n",
    "import sys\n",
    "# GLOBAL\n",
    "\n",
    "#root = os.getcwd()\n",
    "root = '/home/joao/Projeto/Deep_Fashion_Project/'\n",
    "dataset_folder_path = os.path.join(root, 'Dataset')\n",
    "\n",
    "Anno_path = os.path.join(dataset_folder_path, 'Anno')\n",
    "list_attr_cloth = os.path.join(Anno_path, 'list_attr_cloth.txt')\n",
    "list_attr_items = os.path.join(Anno_path, 'list_attr_items.txt')\n",
    "list_attr_type = os.path.join(Anno_path, 'list_attr_type.txt')\n",
    "list_bbox_consumer2shop = os.path.join(Anno_path, 'list_bbox_consumer2shop.txt')\n",
    "list_item_consumer2shop = os.path.join(Anno_path, 'list_item_consumer2shop.txt')\n",
    "list_landmarks_consumer2shop = os.path.join(Anno_path, 'list_landmarks_consumer2shop.txt')\n",
    "\n",
    "Eval_path = os.path.join(dataset_folder_path, 'Eval')\n",
    "list_eval_partition = os.path.join(Eval_path, 'list_eval_partition.txt')\n",
    "\n",
    "Img_path = os.path.join(dataset_folder_path, 'Img')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "#from config import *\n",
    "\n",
    "# Return list of lists [category_id, 'category_name_string', category_type_id]\n",
    "\n",
    "\n",
    "def get_category_id_name_type(path_list_attr_cloth):\n",
    "    category_list = []\n",
    "    with codecs.open(path_list_attr_cloth, 'r', 'utf-8') as file_list_attr_clothes:\n",
    "        next(file_list_attr_clothes)\n",
    "        next(file_list_attr_clothes)\n",
    "        for idx, line in enumerate(file_list_attr_clothes, 1):\n",
    "            category_name = line[24:66].strip().replace(' ', '_').upper()\n",
    "            category_attribute_type = int(line[-5:].strip())\n",
    "            category_list.append([idx, category_name, category_attribute_type])\n",
    "    return category_list\n",
    "\n",
    "\n",
    "# Return dictionary attr_type_dict = {'category_type_id': 'category_type_name'}\n",
    "def generate_attr_type_dict(path_list_attr_type):\n",
    "    attr_type_dict = dict()\n",
    "    with codecs.open(path_list_attr_type, 'r', 'utf-8') as file_list_attr_clothes:\n",
    "        next(file_list_attr_clothes)\n",
    "        next(file_list_attr_clothes)\n",
    "        for idx, line in enumerate(file_list_attr_clothes, 1):\n",
    "            attr_type_name = line[-37:].strip().replace(' ', '_').upper()\n",
    "            attr_type_dict[idx] = attr_type_name\n",
    "    return attr_type_dict\n",
    "\n",
    "\n",
    "# merge into list of lists [category_id, 'category_name_string', category_type_id, 'category_type_id']\n",
    "def merge_attr_types_names(attr_type_dict, category_list):\n",
    "    for category_id in category_list:\n",
    "        category_id.append(attr_type_dict[category_id[-1]])\n",
    "    return category_list\n",
    "\n",
    "\n",
    "# build three sets with unique item ids according to train/test/eval partition\n",
    "def get_item_ids_partition_sets(path_list_eval_partition):\n",
    "    train_ids = set()\n",
    "    val_ids = set()\n",
    "    test_ids = set()\n",
    "    with codecs.open(path_list_eval_partition, 'r', 'utf-8') as file_list_eval_partition:\n",
    "        next(file_list_eval_partition)\n",
    "        next(file_list_eval_partition)\n",
    "        for line in file_list_eval_partition:\n",
    "            if line.split()[3] == 'train':\n",
    "                train_ids.add(line.split()[2])\n",
    "            elif line.split()[3] == 'val':\n",
    "                val_ids.add(line.split()[2])\n",
    "            else:\n",
    "                test_ids.add(line.split()[2])\n",
    "    return train_ids, val_ids, test_ids\n",
    "\n",
    "#creates databse with all path of images and its partition group\n",
    "def gen_processed_list_eval_partition(path_list_eval_partition):\n",
    "    df_list_eval_partition = pd.read_table(path_list_eval_partition,\n",
    "                                           delim_whitespace=True, skiprows=0, header=1)\n",
    "    consumer_files = df_list_eval_partition.drop('image_pair_name_2', axis=1).drop_duplicates()\n",
    "    consumer_files = consumer_files.rename(columns={'image_pair_name_1': 'image_name'})\n",
    "    shop_files = df_list_eval_partition.drop('image_pair_name_1', axis=1).drop_duplicates()\n",
    "    shop_files = shop_files.rename(columns={'image_pair_name_2': 'image_name'})\n",
    "    processed_list_eval_partition = consumer_files.append(shop_files, ignore_index=True)\n",
    "    return processed_list_eval_partition\n",
    "\n",
    "#Generate database with all annotatios\n",
    "def gen_full_anno(path_list_eval_partition, path_list_landmarks_consumer2shop,\n",
    "                  path_list_bbox_consumer2shop, path_list_attr_items,\n",
    "                  bbox=True, item_features = True):\n",
    "    processed_list_eval_partition = gen_processed_list_eval_partition(path_list_eval_partition)\n",
    "    landmarks_consumer2shop = pd.read_table(path_list_landmarks_consumer2shop,\n",
    "                                            delim_whitespace=True, skiprows=0, header=1)\n",
    "    full_anno = processed_list_eval_partition.merge(landmarks_consumer2shop,\n",
    "                                                    how='inner', on='image_name')\n",
    "    if bbox:\n",
    "        bbox_consumer2shop = pd.read_table(path_list_bbox_consumer2shop,\n",
    "                                                delim_whitespace=True, skiprows=0, header=1)\n",
    "        full_anno = full_anno.merge(bbox_consumer2shop, how='inner', on='image_name')\n",
    "    if item_features:\n",
    "        col = ['item_id'] + ['Attr' + str(i) for i in range(1, 304)]\n",
    "        attr_consumer2shop = pd.read_table(path_list_attr_items,\n",
    "                                                delim_whitespace=True, skiprows=2, header=None, names=col)\n",
    "        full_anno = full_anno.merge(attr_consumer2shop,how='outer', on='item_id', validate=\"m:1\")\n",
    "    return full_anno\n",
    "#Select folder of images\n",
    "def gets_from_scope(full_anno,CLOTHING = True, DRESSES=True, TOPS=True, TROUSERS=True ):\n",
    "    full_anno['folders'] = full_anno.image_name.str.split('/').str[1]\n",
    "    if not CLOTHING:\n",
    "        full_anno = full_anno[full_anno.folders != 'CLOTHING']\n",
    "    if not DRESSES:\n",
    "        full_anno = full_anno[full_anno.folders != 'DRESSES']\n",
    "    if not TOPS:\n",
    "        full_anno = full_anno[full_anno.folders != 'TOPS']\n",
    "    if not TROUSERS:\n",
    "        full_anno = full_anno[full_anno.folders != 'TROUSERS']\n",
    "    return full_anno\n",
    "#split database in train, eval and test\n",
    "def split_full_anno(df_full_anno):\n",
    "    train = df_full_anno[df_full_anno.evaluation_status == 'train']\n",
    "    eval = df_full_anno[df_full_anno.evaluation_status == 'eval']\n",
    "    test = df_full_anno[df_full_anno.evaluation_status == 'test']\n",
    "    return train, eval, test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "if __name__ == '__main__':\n",
    "\n",
    "    category_list = get_category_id_name_type(list_attr_cloth)\n",
    "    attr_type_dict = generate_attr_type_dict(list_attr_type)\n",
    "    category_data = merge_attr_types_names(attr_type_dict, category_list)\n",
    "    train_ids_set, val_ids_set, test_ids_set = get_item_ids_partition_sets(list_eval_partition)\n",
    "    df_full_anno = gen_full_anno(list_eval_partition, list_landmarks_consumer2shop,\n",
    "                  list_bbox_consumer2shop, list_attr_items, item_features= True)\n",
    "    clothing_full = gets_from_scope(df_full_anno, True, False, False, False)\n",
    "    df_train, df_eval, df_test = split_full_anno(clothing_full)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "train    6096\n",
       "test     3371\n",
       "val      3110\n",
       "Name: evaluation_status, dtype: int64"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clothing_full.evaluation_status.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "95.53347206115723"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train = df_train.image_name.tolist()\n",
    "#del(df_train, df_full_anno,df_eval,df_test\n",
    "\n",
    "t0 = time.time()\n",
    "data_train = [(cv2.imread(os.path.join(Img_path,fname))) for fname in train]\n",
    "with open('data_train.pkl', 'wb') as f:\n",
    "    pickle.dump(data_train, f)\n",
    "(time.time() - t0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open('data_train.pkl', 'rb') as f:\n",
    "    data_train = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image_name</th>\n",
       "      <th>item_id</th>\n",
       "      <th>evaluation_status</th>\n",
       "      <th>clothes_type_x</th>\n",
       "      <th>variation_type</th>\n",
       "      <th>landmark_visibility_1</th>\n",
       "      <th>landmark_location_x_1</th>\n",
       "      <th>landmark_location_y_1</th>\n",
       "      <th>landmark_visibility_2</th>\n",
       "      <th>landmark_location_x_2</th>\n",
       "      <th>...</th>\n",
       "      <th>Attr295</th>\n",
       "      <th>Attr296</th>\n",
       "      <th>Attr297</th>\n",
       "      <th>Attr298</th>\n",
       "      <th>Attr299</th>\n",
       "      <th>Attr300</th>\n",
       "      <th>Attr301</th>\n",
       "      <th>Attr302</th>\n",
       "      <th>Attr303</th>\n",
       "      <th>folders</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>img/TOPS/T_Shirt/id_00000001/comsumer_01.jpg</td>\n",
       "      <td>id_00000001</td>\n",
       "      <td>test</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>51</td>\n",
       "      <td>92</td>\n",
       "      <td>1</td>\n",
       "      <td>117</td>\n",
       "      <td>...</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>TOPS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>img/TOPS/T_Shirt/id_00000001/comsumer_02.jpg</td>\n",
       "      <td>id_00000001</td>\n",
       "      <td>test</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>56</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>155</td>\n",
       "      <td>...</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>TOPS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>img/TOPS/T_Shirt/id_00000001/comsumer_03.jpg</td>\n",
       "      <td>id_00000001</td>\n",
       "      <td>test</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>76</td>\n",
       "      <td>66</td>\n",
       "      <td>0</td>\n",
       "      <td>125</td>\n",
       "      <td>...</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>TOPS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>img/TOPS/T_Shirt/id_00000001/comsumer_04.jpg</td>\n",
       "      <td>id_00000001</td>\n",
       "      <td>test</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>58</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>160</td>\n",
       "      <td>...</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>TOPS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>img/TOPS/T_Shirt/id_00000001/comsumer_05.jpg</td>\n",
       "      <td>id_00000001</td>\n",
       "      <td>test</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>74</td>\n",
       "      <td>21</td>\n",
       "      <td>0</td>\n",
       "      <td>140</td>\n",
       "      <td>...</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>TOPS</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 339 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     image_name      item_id  \\\n",
       "0  img/TOPS/T_Shirt/id_00000001/comsumer_01.jpg  id_00000001   \n",
       "1  img/TOPS/T_Shirt/id_00000001/comsumer_02.jpg  id_00000001   \n",
       "2  img/TOPS/T_Shirt/id_00000001/comsumer_03.jpg  id_00000001   \n",
       "3  img/TOPS/T_Shirt/id_00000001/comsumer_04.jpg  id_00000001   \n",
       "4  img/TOPS/T_Shirt/id_00000001/comsumer_05.jpg  id_00000001   \n",
       "\n",
       "  evaluation_status  clothes_type_x  variation_type  landmark_visibility_1  \\\n",
       "0              test               1               2                      0   \n",
       "1              test               1               2                      0   \n",
       "2              test               1               2                      0   \n",
       "3              test               1               2                      0   \n",
       "4              test               1               2                      0   \n",
       "\n",
       "   landmark_location_x_1  landmark_location_y_1  landmark_visibility_2  \\\n",
       "0                     51                     92                      1   \n",
       "1                     56                      4                      0   \n",
       "2                     76                     66                      0   \n",
       "3                     58                      7                      0   \n",
       "4                     74                     21                      0   \n",
       "\n",
       "   landmark_location_x_2   ...     Attr295  Attr296  Attr297  Attr298  \\\n",
       "0                    117   ...          -1       -1       -1       -1   \n",
       "1                    155   ...          -1       -1       -1       -1   \n",
       "2                    125   ...          -1       -1       -1       -1   \n",
       "3                    160   ...          -1       -1       -1       -1   \n",
       "4                    140   ...          -1       -1       -1       -1   \n",
       "\n",
       "   Attr299  Attr300  Attr301  Attr302  Attr303  folders  \n",
       "0       -1       -1       -1       -1       -1     TOPS  \n",
       "1       -1       -1       -1       -1       -1     TOPS  \n",
       "2       -1       -1       -1       -1       -1     TOPS  \n",
       "3       -1       -1       -1       -1       -1     TOPS  \n",
       "4       -1       -1       -1       -1       -1     TOPS  \n",
       "\n",
       "[5 rows x 339 columns]"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_full_anno.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
